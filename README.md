# Super-Mario-RL-Agent


In this project we trained a Super Mario Agent to complete a level of Super Mario world. We studied different Deep Q net architectures and found that Double DQN greatly outperformed the rest. The implementation of the Double DQN is above with a report to explain our ideas, process, and findings. I have attached weights that were used for transfer learning purposes to study the generalization to other Mario World Levels. In addition there are weights that involve testing varying level of epsilon, epsilon decay, and lower bounds of epsilon. Refer to the paper for details on what these weights are and can be used for.
